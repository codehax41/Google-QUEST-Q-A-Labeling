{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/universalsentenceencoderlarge4/saved_model.pb\n",
      "/kaggle/input/universalsentenceencoderlarge4/variables/variables.data-00000-of-00001\n",
      "/kaggle/input/universalsentenceencoderlarge4/variables/variables.index\n",
      "/kaggle/input/google-quest-challenge/train.csv\n",
      "/kaggle/input/google-quest-challenge/sample_submission.csv\n",
      "/kaggle/input/google-quest-challenge/test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub #to re use existing models of ML\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from keras.optimizers import *\n",
    "from keras import Model\n",
    "\n",
    "import pickle    \n",
    "import os\n",
    "\n",
    "def save_obj(obj, name ):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "def load_obj(name ):\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "                \n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/google-quest-challenge/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/google-quest-challenge/test.csv')\n",
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "\n",
    "module_url = \"/kaggle/input/universalsentenceencoderlarge4/\"\n",
    "embed = hub.load(module_url)\n",
    "# For the keras Lambda\n",
    "def UniversalEmbedding(x):\n",
    "    results = embed(tf.squeeze(tf.cast(x, tf.string)))[\"outputs\"]\n",
    "    print(results)\n",
    "    return keras.backend.concatenate([results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup training data\n",
    "targets = [\n",
    "        'question_asker_intent_understanding',\n",
    "        'question_body_critical',\n",
    "        'question_conversational',\n",
    "        'question_expect_short_answer',\n",
    "        'question_fact_seeking',\n",
    "        'question_has_commonly_accepted_answer',\n",
    "        'question_interestingness_others',\n",
    "        'question_interestingness_self',\n",
    "        'question_multi_intent',\n",
    "        'question_not_really_a_question',\n",
    "        'question_opinion_seeking',\n",
    "        'question_type_choice',\n",
    "        'question_type_compare',\n",
    "        'question_type_consequence',\n",
    "        'question_type_definition',\n",
    "        'question_type_entity',\n",
    "        'question_type_instructions',\n",
    "        'question_type_procedure',\n",
    "        'question_type_reason_explanation',\n",
    "        'question_type_spelling',\n",
    "        'question_well_written',\n",
    "        'answer_helpful',\n",
    "        'answer_level_of_information',\n",
    "        'answer_plausible',\n",
    "        'answer_relevance',\n",
    "        'answer_satisfaction',\n",
    "        'answer_type_instructions',\n",
    "        'answer_type_procedure',\n",
    "        'answer_type_reason_explanation',\n",
    "        'answer_well_written'    \n",
    "    ]\n",
    "\n",
    "input_columns = ['question_title','question_body','answer']\n",
    "\n",
    "X1 = train[input_columns[0]].values.tolist()\n",
    "X2 = train[input_columns[1]].values.tolist()\n",
    "X3 = train[input_columns[2]].values.tolist()\n",
    "X1 = [x.replace('?','.').replace('!','.') for x in X1]\n",
    "X2 = [x.replace('?','.').replace('!','.') for x in X2]\n",
    "X3 = [x.replace('?','.').replace('!','.') for x in X3]\n",
    "\n",
    "X = [X1,X2,X3]\n",
    "y = train[targets].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"lambda_1/StatefulPartitionedCall:0\", shape=(None, 512), dtype=float32)\n",
      "Tensor(\"lambda_2/StatefulPartitionedCall:0\", shape=(None, 512), dtype=float32)\n",
      "Tensor(\"lambda_3/StatefulPartitionedCall:0\", shape=(None, 512), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# build network\n",
    "def swish(x):\n",
    "    return K.sigmoid(x) * x\n",
    "\n",
    "embed_size = 512 #must be 512 for univerasl embedding layer\n",
    "\n",
    "input_text1 = Input(shape=(1,), dtype=tf.string)\n",
    "embedding1 = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text1)\n",
    "input_text2 = Input(shape=(1,), dtype=tf.string)\n",
    "embedding2 = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text2)\n",
    "input_text3 = Input(shape=(1,), dtype=tf.string)\n",
    "embedding3 = Lambda(UniversalEmbedding, output_shape=(embed_size,))(input_text3)\n",
    "\n",
    "x = Concatenate()([embedding1,embedding2,embedding3])\n",
    "x = Dense(256, activation=swish)(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation=swish, kernel_regularizer=keras.regularizers.l2(0.001))(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = BatchNormalization()(x)\n",
    "output = Dense(len(targets),activation='sigmoid',name='output')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 512)          0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 512)          0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 512)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1536)         0           lambda_1[0][0]                   \n",
      "                                                                 lambda_2[0][0]                   \n",
      "                                                                 lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          393472      concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 256)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 256)          1024        dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 64)           16448       batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 64)           0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 64)           256         dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 30)           1950        batch_normalization_2[0][0]      \n",
      "==================================================================================================\n",
      "Total params: 413,150\n",
      "Trainable params: 412,510\n",
      "Non-trainable params: 640\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs=[input_text1,input_text2,input_text3], outputs=[output])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "Train on 5471 samples, validate on 608 samples\n",
      "Epoch 1/20\n",
      "5471/5471 [==============================] - 136s 25ms/step - loss: 0.6930 - val_loss: 0.4941\n",
      "Epoch 2/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.4585 - val_loss: 0.4505\n",
      "Epoch 3/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.4203 - val_loss: 0.4169\n",
      "Epoch 4/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.4011 - val_loss: 0.3960\n",
      "Epoch 5/20\n",
      "5471/5471 [==============================] - 67s 12ms/step - loss: 0.3914 - val_loss: 0.3869\n",
      "Epoch 6/20\n",
      "5471/5471 [==============================] - 65s 12ms/step - loss: 0.3852 - val_loss: 0.3828\n",
      "Epoch 7/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3809 - val_loss: 0.3798\n",
      "Epoch 8/20\n",
      "5471/5471 [==============================] - 65s 12ms/step - loss: 0.3794 - val_loss: 0.3791\n",
      "Epoch 9/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3774 - val_loss: 0.3781\n",
      "Epoch 10/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3754 - val_loss: 0.3779\n",
      "Epoch 11/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3749 - val_loss: 0.3775\n",
      "Epoch 12/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3740 - val_loss: 0.3764\n",
      "Epoch 13/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3726 - val_loss: 0.3766\n",
      "Epoch 14/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3728 - val_loss: 0.3768\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.1.\n",
      "Epoch 15/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3693 - val_loss: 0.3761\n",
      "Epoch 16/20\n",
      "5471/5471 [==============================] - 65s 12ms/step - loss: 0.3686 - val_loss: 0.3759\n",
      "Epoch 17/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3681 - val_loss: 0.3758\n",
      "Epoch 18/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3679 - val_loss: 0.3755\n",
      "Epoch 19/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3679 - val_loss: 0.3755\n",
      "Epoch 20/20\n",
      "5471/5471 [==============================] - 66s 12ms/step - loss: 0.3667 - val_loss: 0.3755\n",
      "\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.010000000149011612.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f55062e2eb8>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean up as much as possible\n",
    "import gc\n",
    "print(gc.collect())\n",
    "# Train the network\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
    "                              patience=2, min_lr=1e-7, verbose=1)\n",
    "optimizer = Adadelta()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
    "model.fit(X, [y], epochs=20, validation_split=.1,batch_size=32,callbacks=[reduce_lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>qa_id</th>\n",
       "      <th>question_asker_intent_understanding</th>\n",
       "      <th>question_body_critical</th>\n",
       "      <th>question_conversational</th>\n",
       "      <th>question_expect_short_answer</th>\n",
       "      <th>question_fact_seeking</th>\n",
       "      <th>question_has_commonly_accepted_answer</th>\n",
       "      <th>question_interestingness_others</th>\n",
       "      <th>question_interestingness_self</th>\n",
       "      <th>question_multi_intent</th>\n",
       "      <th>...</th>\n",
       "      <th>question_well_written</th>\n",
       "      <th>answer_helpful</th>\n",
       "      <th>answer_level_of_information</th>\n",
       "      <th>answer_plausible</th>\n",
       "      <th>answer_relevance</th>\n",
       "      <th>answer_satisfaction</th>\n",
       "      <th>answer_type_instructions</th>\n",
       "      <th>answer_type_procedure</th>\n",
       "      <th>answer_type_reason_explanation</th>\n",
       "      <th>answer_well_written</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>0.924706</td>\n",
       "      <td>0.717970</td>\n",
       "      <td>0.361762</td>\n",
       "      <td>0.757099</td>\n",
       "      <td>0.469510</td>\n",
       "      <td>0.595545</td>\n",
       "      <td>0.656191</td>\n",
       "      <td>0.611598</td>\n",
       "      <td>0.214955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878272</td>\n",
       "      <td>0.928102</td>\n",
       "      <td>0.668519</td>\n",
       "      <td>0.967651</td>\n",
       "      <td>0.971278</td>\n",
       "      <td>0.856516</td>\n",
       "      <td>0.023118</td>\n",
       "      <td>0.048309</td>\n",
       "      <td>0.938198</td>\n",
       "      <td>0.930954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>46</td>\n",
       "      <td>0.872782</td>\n",
       "      <td>0.555062</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.633589</td>\n",
       "      <td>0.912243</td>\n",
       "      <td>0.939106</td>\n",
       "      <td>0.555607</td>\n",
       "      <td>0.441975</td>\n",
       "      <td>0.188445</td>\n",
       "      <td>...</td>\n",
       "      <td>0.794167</td>\n",
       "      <td>0.930423</td>\n",
       "      <td>0.622766</td>\n",
       "      <td>0.957904</td>\n",
       "      <td>0.971309</td>\n",
       "      <td>0.844175</td>\n",
       "      <td>0.878718</td>\n",
       "      <td>0.197939</td>\n",
       "      <td>0.163132</td>\n",
       "      <td>0.891977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70</td>\n",
       "      <td>0.898625</td>\n",
       "      <td>0.622473</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.759433</td>\n",
       "      <td>0.886882</td>\n",
       "      <td>0.905188</td>\n",
       "      <td>0.594162</td>\n",
       "      <td>0.504091</td>\n",
       "      <td>0.371287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.838177</td>\n",
       "      <td>0.924725</td>\n",
       "      <td>0.637207</td>\n",
       "      <td>0.965682</td>\n",
       "      <td>0.967866</td>\n",
       "      <td>0.843614</td>\n",
       "      <td>0.205841</td>\n",
       "      <td>0.085576</td>\n",
       "      <td>0.729787</td>\n",
       "      <td>0.915010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>132</td>\n",
       "      <td>0.853233</td>\n",
       "      <td>0.409977</td>\n",
       "      <td>0.005684</td>\n",
       "      <td>0.709513</td>\n",
       "      <td>0.863309</td>\n",
       "      <td>0.925419</td>\n",
       "      <td>0.556805</td>\n",
       "      <td>0.453179</td>\n",
       "      <td>0.362997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.701090</td>\n",
       "      <td>0.947137</td>\n",
       "      <td>0.688902</td>\n",
       "      <td>0.971202</td>\n",
       "      <td>0.980154</td>\n",
       "      <td>0.881700</td>\n",
       "      <td>0.683100</td>\n",
       "      <td>0.177826</td>\n",
       "      <td>0.753380</td>\n",
       "      <td>0.908707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200</td>\n",
       "      <td>0.917019</td>\n",
       "      <td>0.601920</td>\n",
       "      <td>0.017630</td>\n",
       "      <td>0.830541</td>\n",
       "      <td>0.825950</td>\n",
       "      <td>0.917814</td>\n",
       "      <td>0.598242</td>\n",
       "      <td>0.532566</td>\n",
       "      <td>0.308121</td>\n",
       "      <td>...</td>\n",
       "      <td>0.829304</td>\n",
       "      <td>0.948070</td>\n",
       "      <td>0.678869</td>\n",
       "      <td>0.972736</td>\n",
       "      <td>0.975923</td>\n",
       "      <td>0.886673</td>\n",
       "      <td>0.435941</td>\n",
       "      <td>0.145375</td>\n",
       "      <td>0.478650</td>\n",
       "      <td>0.917339</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   qa_id  question_asker_intent_understanding  question_body_critical  \\\n",
       "0     39                             0.924706                0.717970   \n",
       "1     46                             0.872782                0.555062   \n",
       "2     70                             0.898625                0.622473   \n",
       "3    132                             0.853233                0.409977   \n",
       "4    200                             0.917019                0.601920   \n",
       "\n",
       "   question_conversational  question_expect_short_answer  \\\n",
       "0                 0.361762                      0.757099   \n",
       "1                 0.002280                      0.633589   \n",
       "2                 0.018558                      0.759433   \n",
       "3                 0.005684                      0.709513   \n",
       "4                 0.017630                      0.830541   \n",
       "\n",
       "   question_fact_seeking  question_has_commonly_accepted_answer  \\\n",
       "0               0.469510                               0.595545   \n",
       "1               0.912243                               0.939106   \n",
       "2               0.886882                               0.905188   \n",
       "3               0.863309                               0.925419   \n",
       "4               0.825950                               0.917814   \n",
       "\n",
       "   question_interestingness_others  question_interestingness_self  \\\n",
       "0                         0.656191                       0.611598   \n",
       "1                         0.555607                       0.441975   \n",
       "2                         0.594162                       0.504091   \n",
       "3                         0.556805                       0.453179   \n",
       "4                         0.598242                       0.532566   \n",
       "\n",
       "   question_multi_intent  ...  question_well_written  answer_helpful  \\\n",
       "0               0.214955  ...               0.878272        0.928102   \n",
       "1               0.188445  ...               0.794167        0.930423   \n",
       "2               0.371287  ...               0.838177        0.924725   \n",
       "3               0.362997  ...               0.701090        0.947137   \n",
       "4               0.308121  ...               0.829304        0.948070   \n",
       "\n",
       "   answer_level_of_information  answer_plausible  answer_relevance  \\\n",
       "0                     0.668519          0.967651          0.971278   \n",
       "1                     0.622766          0.957904          0.971309   \n",
       "2                     0.637207          0.965682          0.967866   \n",
       "3                     0.688902          0.971202          0.980154   \n",
       "4                     0.678869          0.972736          0.975923   \n",
       "\n",
       "   answer_satisfaction  answer_type_instructions  answer_type_procedure  \\\n",
       "0             0.856516                  0.023118               0.048309   \n",
       "1             0.844175                  0.878718               0.197939   \n",
       "2             0.843614                  0.205841               0.085576   \n",
       "3             0.881700                  0.683100               0.177826   \n",
       "4             0.886673                  0.435941               0.145375   \n",
       "\n",
       "   answer_type_reason_explanation  answer_well_written  \n",
       "0                        0.938198             0.930954  \n",
       "1                        0.163132             0.891977  \n",
       "2                        0.729787             0.915010  \n",
       "3                        0.753380             0.908707  \n",
       "4                        0.478650             0.917339  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prep test data\n",
    "X1 = test[input_columns[0]].values.tolist()\n",
    "X2 = test[input_columns[1]].values.tolist()\n",
    "X3 = test[input_columns[2]].values.tolist()\n",
    "X1 = [x.replace('?','.').replace('!','.') for x in X1]\n",
    "X2 = [x.replace('?','.').replace('!','.') for x in X2]\n",
    "X3 = [x.replace('?','.').replace('!','.') for x in X3]\n",
    "\n",
    "pred_X = [X1,X2,X3]\n",
    "# Make a prediction\n",
    "pred_y = model.predict(pred_X)\n",
    "# Check the submission\n",
    "submission = pd.read_csv('/kaggle/input/google-quest-challenge/sample_submission.csv')\n",
    "submission[targets] = pred_y\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the result\n",
    "submission.to_csv(\"submission.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
